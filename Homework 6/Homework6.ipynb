{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\tEvaluate text similarity of Amazon book search results by doing the following:\n",
    "##### a.\tDo a book search on Amazon. Manually copy the full book title (including subtitle) of each of the top 24 books listed in the first two pages of search results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Testaments: The Sequel to The Handmaid's Tale\",\n",
       " 'The Nickel Boys: A Novel',\n",
       " 'Wild Game: My Mother, Her Lover, and Me',\n",
       " 'Quichotte: A Novel',\n",
       " 'The Starless Sea: A Novel',\n",
       " 'Super Pumped: The Battle for Uber',\n",
       " 'City of Girls: A Novel',\n",
       " 'They Called Us Enemy',\n",
       " 'The Silent Patient',\n",
       " 'Maybe You Should Talk to Someone: A Therapist, HER Therapist, and Our Lives Revealed',\n",
       " 'The Dutch House: A Novel',\n",
       " 'Red at the Bone: A Novel',\n",
       " 'Ask Again, Yes: A Novel',\n",
       " 'The World That We Knew: A Novel',\n",
       " \"On Earth We're Briefly Gorgeous: A Novel\",\n",
       " 'I Will Never See the World Again: The Memoir of an Imprisoned Writer',\n",
       " \"The Water Dancer (Oprah's Book Club): A Novel\",\n",
       " 'Ninth House (Alex Stern)',\n",
       " 'Three Women',\n",
       " \"Things We Didn't Talk About When I Was a Girl: A Memoir\",\n",
       " 'Save Me the Plums: My Gourmet Memoir',\n",
       " 'A Woman Is No Man: A Novel',\n",
       " 'Once More We Saw Stars: A Memoir',\n",
       " 'Mrs. Everything: A Novel']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_books2019 = [\n",
    "                \"The Testaments: The Sequel to The Handmaid's Tale\",\n",
    "                \"The Nickel Boys: A Novel\",\n",
    "                \"Wild Game: My Mother, Her Lover, and Me\",\n",
    "                \"Quichotte: A Novel\",\n",
    "                \"The Starless Sea: A Novel\",\n",
    "                \"Super Pumped: The Battle for Uber\",\n",
    "                \"City of Girls: A Novel\",\n",
    "                \"They Called Us Enemy\",\n",
    "                \"The Silent Patient\",\n",
    "                \"Maybe You Should Talk to Someone: A Therapist, HER Therapist, and Our Lives Revealed\",\n",
    "                \"The Dutch House: A Novel\",\n",
    "                \"Red at the Bone: A Novel\",\n",
    "                \"Ask Again, Yes: A Novel\",\n",
    "                \"The World That We Knew: A Novel\",\n",
    "                \"On Earth We're Briefly Gorgeous: A Novel\",\n",
    "                \"I Will Never See the World Again: The Memoir of an Imprisoned Writer\",\n",
    "                \"The Water Dancer (Oprah's Book Club): A Novel\",\n",
    "                \"Ninth House (Alex Stern)\",\n",
    "                \"Three Women\",\n",
    "                \"Things We Didn't Talk About When I Was a Girl: A Memoir\",\n",
    "                \"Save Me the Plums: My Gourmet Memoir\",\n",
    "                \"A Woman Is No Man: A Novel\",\n",
    "                \"Once More We Saw Stars: A Memoir\",\n",
    "                \"Mrs. Everything: A Novel\"\n",
    "               ]\n",
    "\n",
    "best_books2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  b) Compare each of the book titles based on cosine similarity, pairwise, to every other one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "\n",
    "book_list_tokenized = []\n",
    "\n",
    "for book in best_books2019:\n",
    "    text = word_tokenize(book)\n",
    "    book_list_tokenized.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<24x96 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 133 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the titles using CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit_transform(best_books2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 76, 'testaments': 74, 'sequel': 64, 'to': 81, 'handmaid': 27, 'tale': 72, 'nickel': 44, 'boys': 10, 'novel': 47, 'wild': 88, 'game': 22, 'my': 42, 'mother': 40, 'her': 28, 'lover': 34, 'and': 4, 'me': 37, 'quichotte': 56, 'starless': 68, 'sea': 62, 'super': 71, 'pumped': 55, 'battle': 7, 'for': 21, 'uber': 82, 'city': 13, 'of': 48, 'girls': 24, 'they': 78, 'called': 12, 'us': 83, 'enemy': 19, 'silent': 66, 'patient': 53, 'maybe': 36, 'you': 95, 'should': 65, 'talk': 73, 'someone': 67, 'therapist': 77, 'our': 52, 'lives': 33, 'revealed': 59, 'dutch': 17, 'house': 29, 'red': 58, 'at': 6, 'bone': 8, 'ask': 5, 'again': 1, 'yes': 94, 'world': 92, 'that': 75, 'we': 86, 'knew': 32, 'on': 49, 'earth': 18, 're': 57, 'briefly': 11, 'gorgeous': 25, 'will': 89, 'never': 43, 'see': 63, 'memoir': 38, 'an': 3, 'imprisoned': 30, 'writer': 93, 'water': 85, 'dancer': 15, 'oprah': 51, 'book': 9, 'club': 14, 'ninth': 45, 'alex': 2, 'stern': 70, 'three': 80, 'women': 91, 'things': 79, 'didn': 16, 'about': 0, 'when': 87, 'was': 84, 'girl': 23, 'save': 60, 'plums': 54, 'gourmet': 26, 'woman': 90, 'is': 31, 'no': 46, 'man': 35, 'once': 50, 'more': 39, 'saw': 61, 'stars': 69, 'mrs': 41, 'everything': 20}\n"
     ]
    }
   ],
   "source": [
    "print(count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 96)\n"
     ]
    }
   ],
   "source": [
    "tf_matrix = count_vectorizer.transform(best_books2019).toarray()\n",
    "tfidfTran = TfidfTransformer(norm=\"l2\")\n",
    "tfidfTran.fit(tf_matrix)\n",
    "tfidf_matrix = tfidfTran.transform(tf_matrix)\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.17529189 0.         0.         0.17529189 0.12013134\n",
      "  0.         0.         0.18369366 0.07897009 0.18355948 0.14782248\n",
      "  0.         0.1412254  0.         0.17513895 0.11768647 0.\n",
      "  0.         0.         0.11884363 0.         0.         0.        ]\n",
      " [0.17529189 1.         0.         0.12697169 0.18762868 0.0673293\n",
      "  0.08092806 0.         0.10295369 0.         0.19647814 0.15822602\n",
      "  0.08092806 0.15116464 0.05839705 0.09815908 0.12596907 0.\n",
      "  0.         0.         0.06660758 0.06827124 0.         0.09412714]\n",
      " [0.         0.         1.         0.         0.         0.\n",
      "  0.         0.         0.         0.15601511 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.25343026 0.         0.         0.        ]\n",
      " [0.         0.12697169 0.         1.         0.12697169 0.\n",
      "  0.11496001 0.         0.         0.         0.13296028 0.10707438\n",
      "  0.11496001 0.10229583 0.08295424 0.         0.08524553 0.\n",
      "  0.         0.         0.         0.09698074 0.         0.1337096 ]\n",
      " [0.17529189 0.18762868 0.         0.12697169 1.         0.0673293\n",
      "  0.08092806 0.         0.10295369 0.         0.19647814 0.15822602\n",
      "  0.08092806 0.15116464 0.05839705 0.09815908 0.12596907 0.\n",
      "  0.         0.         0.06660758 0.06827124 0.         0.09412714]\n",
      " [0.12013134 0.0673293  0.         0.         0.0673293  1.\n",
      "  0.         0.         0.0705564  0.         0.07050487 0.05677835\n",
      "  0.         0.05424442 0.         0.06727055 0.04520316 0.\n",
      "  0.         0.         0.04564762 0.         0.         0.        ]\n",
      " [0.         0.08092806 0.         0.11496001 0.08092806 0.\n",
      "  1.         0.         0.         0.         0.08474501 0.06824609\n",
      "  0.07327216 0.06520038 0.05287262 0.14389318 0.05433302 0.\n",
      "  0.         0.         0.         0.06181269 0.         0.0852226 ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         1.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.18369366 0.10295369 0.         0.         0.10295369 0.0705564\n",
      "  0.         0.         1.         0.         0.10780947 0.08682016\n",
      "  0.         0.08294551 0.         0.10286386 0.06912046 0.\n",
      "  0.         0.         0.06980009 0.         0.         0.        ]\n",
      " [0.07897009 0.         0.15601511 0.         0.         0.\n",
      "  0.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07422334 0.         0.         0.         0.        ]\n",
      " [0.18355948 0.19647814 0.         0.13296028 0.19647814 0.07050487\n",
      "  0.08474501 0.         0.10780947 0.         1.         0.1656887\n",
      "  0.08474501 0.15829428 0.06115133 0.10278873 0.13191037 0.2687393\n",
      "  0.         0.         0.06974911 0.07149123 0.         0.09856663]\n",
      " [0.14782248 0.15822602 0.         0.10707438 0.15822602 0.05677835\n",
      "  0.06824609 0.         0.08682016 0.         0.1656887  1.\n",
      "  0.06824609 0.12747614 0.04924584 0.0827769  0.10622888 0.\n",
      "  0.         0.         0.05616973 0.05757268 0.         0.07937679]\n",
      " [0.         0.08092806 0.         0.11496001 0.08092806 0.\n",
      "  0.07327216 0.         0.         0.         0.08474501 0.06824609\n",
      "  1.         0.06520038 0.05287262 0.14389318 0.05433302 0.\n",
      "  0.         0.         0.         0.06181269 0.         0.0852226 ]\n",
      " [0.1412254  0.15116464 0.         0.10229583 0.15116464 0.05424442\n",
      "  0.06520038 0.         0.08294551 0.         0.15829428 0.12747614\n",
      "  0.06520038 1.         0.16416064 0.20712437 0.10148806 0.\n",
      "  0.         0.10020298 0.05366296 0.0550033  0.12459901 0.07583434]\n",
      " [0.         0.05839705 0.         0.08295424 0.05839705 0.\n",
      "  0.05287262 0.         0.         0.         0.06115133 0.04924584\n",
      "  0.05287262 0.16416064 1.         0.         0.03920628 0.\n",
      "  0.         0.0812571  0.         0.04460356 0.10104045 0.06149596]\n",
      " [0.17513895 0.09815908 0.         0.         0.09815908 0.06727055\n",
      "  0.14389318 0.         0.10286386 0.         0.10278873 0.0827769\n",
      "  0.14389318 0.20712437 0.         1.         0.06590148 0.\n",
      "  0.         0.06213275 0.14190684 0.         0.07725997 0.        ]\n",
      " [0.11768647 0.12596907 0.         0.08524553 0.12596907 0.04520316\n",
      "  0.05433302 0.         0.06912046 0.         0.13191037 0.10622888\n",
      "  0.05433302 0.10148806 0.03920628 0.06590148 1.         0.\n",
      "  0.         0.         0.04471861 0.04583555 0.         0.06319455]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.2687393  0.\n",
      "  0.         0.         0.         0.         0.         1.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.07422334 0.         0.\n",
      "  0.         0.10020298 0.0812571  0.06213275 0.         0.\n",
      "  0.         1.         0.08432254 0.         0.17290296 0.        ]\n",
      " [0.11884363 0.06660758 0.25343026 0.         0.06660758 0.04564762\n",
      "  0.         0.         0.06980009 0.         0.06974911 0.05616973\n",
      "  0.         0.05366296 0.         0.14190684 0.04471861 0.\n",
      "  0.         0.08432254 1.         0.         0.10485222 0.        ]\n",
      " [0.         0.06827124 0.         0.09698074 0.06827124 0.\n",
      "  0.06181269 0.         0.         0.         0.07149123 0.05757268\n",
      "  0.06181269 0.0550033  0.04460356 0.         0.04583555 0.\n",
      "  0.         0.         0.         1.         0.         0.07189413]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12459901 0.10104045 0.07725997 0.         0.\n",
      "  0.         0.17290296 0.10485222 0.         1.         0.        ]\n",
      " [0.         0.09412714 0.         0.1337096  0.09412714 0.\n",
      "  0.0852226  0.         0.         0.         0.09856663 0.07937679\n",
      "  0.0852226  0.07583434 0.06149596 0.         0.06319455 0.\n",
      "  0.         0.         0.         0.07189413 0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "cos_similarity_matrix = (tfidf_matrix * tfidf_matrix.T).toarray()\n",
    "print(cos_similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c) Which two titles are the most similar to each other? Which are the most dissimilar? Where do they rank, among the first 24 results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "length, width = cos_similarity_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26873929893960785\n"
     ]
    }
   ],
   "source": [
    "print(cos_similarity_matrix[10,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar book titles have a cosine similarity of 0.26873929893960785\n",
      "The 10 ranked booked is 'The Dutch House: A Novel'\n",
      "The 17 ranked booked is 'Ninth House (Alex Stern)'\n"
     ]
    }
   ],
   "source": [
    "max_value = 0.0\n",
    "row = None\n",
    "col = None\n",
    "\n",
    "for l in range(length):\n",
    "    for w in range(width):\n",
    "        if l == w:\n",
    "            continue\n",
    "        else:\n",
    "            if cos_similarity_matrix[l,w] > max_value: \n",
    "                max_value = cos_similarity_matrix[l,w]\n",
    "                row = l\n",
    "                col = w\n",
    "                \n",
    "        \n",
    "print(\"The most similar book titles have a cosine similarity of {}\".format(max_value))\n",
    "print(\"The {r} ranked booked is '{t}'\".format(r=row, t=best_books2019[row]))\n",
    "print(\"The {c} ranked booked is '{t}'\".format(c=col, t=best_books2019[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The most similiar books were Number 10'The Dutch House: A Novel' and 17 'Ninth House(Alex Stern)' with a cosine similarity of 29%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most dissimilar book titles have a cosine similarity of 0.03920627867468334\n",
      "The 14 ranked booked is 'On Earth We're Briefly Gorgeous: A Novel'\n",
      "The 16 ranked booked is 'The Water Dancer (Oprah's Book Club): A Novel'\n"
     ]
    }
   ],
   "source": [
    "min_value = 1.0\n",
    "row = None\n",
    "col = None\n",
    "\n",
    "for l in range(length):\n",
    "    for w in range(width):\n",
    "        if l == w:\n",
    "            continue\n",
    "        if cos_similarity_matrix[l,w] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if cos_similarity_matrix[l,w] < min_value: \n",
    "                min_value = cos_similarity_matrix[l,w]\n",
    "                row = l\n",
    "                col = w\n",
    "                \n",
    "        \n",
    "print(\"The most dissimilar book titles have a cosine similarity of {}\".format(min_value))\n",
    "print(\"The {r} ranked booked is '{t}'\".format(r=row, t=best_books2019[row]))\n",
    "print(\"The {c} ranked booked is '{t}'\".format(c=col, t=best_books2019[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The most dissimiliar books were Number 14'On Earth We're a Briefly Gorgeous: A Novel' and 16 'The Water Dance (Oprah's Book Club)' with a cosine similarity of 4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\tNow evaluate using a major search engine.\n",
    "##### a.\tEnter one of the book titles from question 1a into Google, Bing, or Yahoo!. Copy the capsule of the first organic result and the 20th organic result. Take web results only (i.e., not video results), and skip sponsored results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_list_Google = [\n",
    "    \"The Testaments: The Sequel to The Handmaid's Tale\", # Book \n",
    "    \"The Testaments is a 2019 novel by Margaret Atwood. It is a sequel to The Handmaid's Tale (1985). The novel is set 15 years after the events of The Handmaid's Tale. It is narrated by Aunt Lydia, a character from the previous novel; Agnes, a young woman living in Gilead; and Daisy, a young woman living in Canada.\", # 1st result from Google\n",
    "    \"Almost 35 years after “The Handmaid's Tale” shocked the world, Margaret Atwood has finally given birth to “The Testaments.”\" #20th result from Google\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b.\tRun the same text similarity calculation that you used for question 1b on each of these capsules in comparison to the original query (book title). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.42947692 0.52043953]\n",
      " [0.42947692 1.         0.3008865 ]\n",
      " [0.52043953 0.3008865  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize titles\n",
    "book_list_Google_tokenized = []\n",
    "\n",
    "for book in book_list_Google:\n",
    "    text = word_tokenize(book)\n",
    "    book_list_Google_tokenized.append(text)\n",
    "    \n",
    "# Vectorize the titles using CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit_transform(book_list_Google)\n",
    "\n",
    "# Create tfidf matrix\n",
    "tf_matrix = count_vectorizer.transform(book_list_Google).toarray()\n",
    "tfidfTran = TfidfTransformer(norm=\"l2\")\n",
    "tfidfTran.fit(tf_matrix)\n",
    "tfidf_matrix = tfidfTran.transform(tf_matrix)\n",
    "\n",
    "# Pairwise\n",
    "search_similarity_matrix = (tfidf_matrix * tfidf_matrix.T).toarray()\n",
    "print(search_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42947692329083703"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_similarity_matrix[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.520439527276546"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_similarity_matrix[0,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The 1st google query had a similiarity around 43% and the 20th around 52%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c.\tWhich one has the highest similarity measure? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\tTake the dataset from Homework 4 and run it through an RNN, an LSTM, and a Bidirectional RNN.\n",
    "###### a.\tReport your accuracy, precision, and F1 for each class (‘O’ counts as a class, ‘PAD’ should be ignored).\n",
    "###### b.  Turn in a Confusion Matrix of your results for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "f = open('train.txt','r')\n",
    "tagged_sentence = []\n",
    "sentence = []\n",
    "\n",
    "for line in f:\n",
    "    if len(line)==0 or line.startswith('-DOCSTART') or line[0]=='\\n':\n",
    "        if len(sentence) >0:\n",
    "            tagged_sentence.append(sentence)\n",
    "            sentence = []\n",
    "        continue\n",
    "    splits = line.split(' ')\n",
    "    splits[-1] = re.sub(r'\\n','',splits[-1])\n",
    "    word = splits[0].lower()\n",
    "    sentence.append([word,splits[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = []\n",
    "tag_list = []\n",
    "\n",
    "for tagged_sentence in tagged_sentence:\n",
    "    sentence, tag_info = zip(*tagged_sentence)\n",
    "    sentence_list.append(list(sentence))\n",
    "    tag_list.append(list(tag_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, TimeDistributed, SimpleRNN\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "max_words = 4000\n",
    "\n",
    "vocab = Tokenizer(num_words=max_words, oov_token='OOV')\n",
    "vocab.fit_on_texts(sentence_list)\n",
    "\n",
    "tag = Tokenizer()\n",
    "tag.fit_on_texts(tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 10\n"
     ]
    }
   ],
   "source": [
    "vocab_size = max_words\n",
    "tag_size = len(tag.word_index) + 1\n",
    "print(vocab_size, tag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vocab.texts_to_sequences(sentence_list)\n",
    "y_train = tag.texts_to_sequences(tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = vocab.index_word\n",
    "index2ner = tag.index_word\n",
    "index2ner[0] = 'PAD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "indextarget = dict([(value, key) for (key, value) in index2ner.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'o': 1,\n",
       " 'b-loc': 2,\n",
       " 'b-per': 3,\n",
       " 'b-org': 4,\n",
       " 'i-per': 5,\n",
       " 'i-org': 6,\n",
       " 'b-misc': 7,\n",
       " 'i-loc': 8,\n",
       " 'i-misc': 9,\n",
       " 'PAD': 0}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indextarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_decoded = []\n",
    "for index in X_train[0] : \n",
    "    ex_decoded.append(index2word[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 70\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "y_train = pad_sequences(y_train, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=tag_size)\n",
    "y_test = to_categorical(y_test, num_classes=tag_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 70, 128)           512000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 70, 500)           314500    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 70, 10)            5010      \n",
      "=================================================================\n",
      "Total params: 831,510\n",
      "Trainable params: 831,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len, mask_zero=True))\n",
    "model.add(SimpleRNN(units=500, return_sequences=True, recurrent_dropout=0.2, dropout=0.2))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy', tf.keras.metrics.Precision(),tf.keras.metrics.Recall()] )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11232 samples, validate on 2809 samples\n",
      "Epoch 1/4\n",
      "11232/11232 [==============================] - 60s 5ms/sample - loss: 0.1747 - acc: 0.8169 - precision_1: 0.8670 - recall_1: 0.7277 - val_loss: 0.1178 - val_acc: 0.8580 - val_precision_1: 0.8941 - val_recall_1: 0.8200\n",
      "Epoch 2/4\n",
      "11232/11232 [==============================] - 57s 5ms/sample - loss: 0.0877 - acc: 0.8772 - precision_1: 0.9346 - recall_1: 0.8292 - val_loss: 0.0666 - val_acc: 0.9096 - val_precision_1: 0.9557 - val_recall_1: 0.8625\n",
      "Epoch 3/4\n",
      "11232/11232 [==============================] - 61s 5ms/sample - loss: 0.0602 - acc: 0.9168 - precision_1: 0.9550 - recall_1: 0.8761 - val_loss: 0.0518 - val_acc: 0.9298 - val_precision_1: 0.9621 - val_recall_1: 0.9018\n",
      "Epoch 4/4\n",
      "11232/11232 [==============================] - 59s 5ms/sample - loss: 0.0486 - acc: 0.9313 - precision_1: 0.9572 - recall_1: 0.9088 - val_loss: 0.0458 - val_acc: 0.9356 - val_precision_1: 0.9558 - val_recall_1: 0.9220\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=4,  validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2809/2809 [==============================] - 9s 3ms/sample - loss: 0.0458 - acc: 0.9356 - precision_1: 0.9558 - recall_1: 0.9220\n",
      "Simple RNN Metrics(Test loss, Test Accuracy, Precision, & Recall): \n",
      "[0.0458189492992826, 0.9356094, 0.95580363, 0.92200196]\n"
     ]
    }
   ],
   "source": [
    "SRNN_metrics = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Simple RNN Metrics(Test loss, Test Accuracy, Precision, & Recall): \")\n",
    "print(SRNN_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 2, 8, 1],\n",
       "       [0, 0, 0, ..., 3, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "y_pred = model.predict(np.array(X_test))\n",
    "y_pred = np.argmax(y_pred,axis=-1)\n",
    "true = np.argmax(np.array(y_test),-1)\n",
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "pred = []\n",
    "actual = []\n",
    "\n",
    "for prediction in range(y_pred.shape[0]):                       \n",
    "    for i in range(max_len):                            \n",
    "        if true[prediction][i]==0:  #skip PAD value so not in DF\n",
    "            pass\n",
    "        else:                                                 \n",
    "            if true[prediction][i]==y_pred[prediction][i]:      \n",
    "                count = count+1                                \n",
    "                total=total+1                                      \n",
    "            pred.append(y_pred[prediction][i])                   \n",
    "            actual.append(true[prediction][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "simpRNNDF = pd.DataFrame(precision_recall_fscore_support(y_true=actual, y_pred=pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>o</th>\n",
       "      <th>b-loc</th>\n",
       "      <th>b-per</th>\n",
       "      <th>b-org</th>\n",
       "      <th>i-per</th>\n",
       "      <th>i-org</th>\n",
       "      <th>b-misc</th>\n",
       "      <th>i-loc</th>\n",
       "      <th>i-misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.948596</td>\n",
       "      <td>0.874613</td>\n",
       "      <td>0.895769</td>\n",
       "      <td>0.862022</td>\n",
       "      <td>0.856957</td>\n",
       "      <td>0.774481</td>\n",
       "      <td>0.778878</td>\n",
       "      <td>0.708738</td>\n",
       "      <td>0.694805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.991879</td>\n",
       "      <td>0.794097</td>\n",
       "      <td>0.692185</td>\n",
       "      <td>0.520627</td>\n",
       "      <td>0.778040</td>\n",
       "      <td>0.359010</td>\n",
       "      <td>0.699259</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.467249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FScore</th>\n",
       "      <td>0.969755</td>\n",
       "      <td>0.832413</td>\n",
       "      <td>0.780927</td>\n",
       "      <td>0.649177</td>\n",
       "      <td>0.815594</td>\n",
       "      <td>0.490602</td>\n",
       "      <td>0.736924</td>\n",
       "      <td>0.626609</td>\n",
       "      <td>0.558747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support</th>\n",
       "      <td>34233.000000</td>\n",
       "      <td>1423.000000</td>\n",
       "      <td>1254.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>727.000000</td>\n",
       "      <td>675.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>229.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      o        b-loc        b-per        b-org       i-per  \\\n",
       "Precision      0.948596     0.874613     0.895769     0.862022    0.856957   \n",
       "Recall         0.991879     0.794097     0.692185     0.520627    0.778040   \n",
       "FScore         0.969755     0.832413     0.780927     0.649177    0.815594   \n",
       "Support    34233.000000  1423.000000  1254.000000  1212.000000  847.000000   \n",
       "\n",
       "                i-org      b-misc       i-loc      i-misc  \n",
       "Precision    0.774481    0.778878    0.708738    0.694805  \n",
       "Recall       0.359010    0.699259    0.561538    0.467249  \n",
       "FScore       0.490602    0.736924    0.626609    0.558747  \n",
       "Support    727.000000  675.000000  260.000000  229.000000  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpRNNDF.index = [\"Precision\", \"Recall\", \"FScore\" ,\"Support\"]\n",
    "simpRNNDF.columns = [index2ner[col] for col in list(set(actual))]\n",
    "simpRNNDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33955,    32,    46,    18,    69,    29,    47,    10,    27],\n",
       "       [  214,  1130,     5,    48,     0,     3,    20,     2,     1],\n",
       "       [  346,     4,   868,    19,    13,     2,     1,     1,     0],\n",
       "       [  417,    78,    29,   631,     1,     5,    45,     2,     4],\n",
       "       [  163,     0,    13,     0,   659,    10,     1,     1,     0],\n",
       "       [  369,    17,     6,     5,    16,   261,     6,    39,     8],\n",
       "       [  166,    18,     2,     8,     0,     3,   472,     1,     5],\n",
       "       [   74,     7,     0,     3,    10,    15,     3,   146,     2],\n",
       "       [   91,     6,     0,     0,     1,     9,    11,     4,   107]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Compute confusion matrix\n",
    "simpRNNMatrix = confusion_matrix(actual, pred)\n",
    "\n",
    "simpRNNMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 70, 128)           512000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 70, 500)           1258000   \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 70, 10)            5010      \n",
      "=================================================================\n",
      "Total params: 1,775,010\n",
      "Trainable params: 1,775,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len, mask_zero=True))\n",
    "model.add(LSTM(units=500, return_sequences=True, recurrent_dropout=0.2, dropout=0.2))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy', tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11232 samples, validate on 2809 samples\n",
      "Epoch 1/4\n",
      "11232/11232 [==============================] - 295s 26ms/sample - loss: 0.1914 - acc: 0.8235 - precision_2: 0.8630 - recall_2: 0.6827 - val_loss: 0.1367 - val_acc: 0.8366 - val_precision_2: 0.8700 - val_recall_2: 0.8102\n",
      "Epoch 2/4\n",
      "11232/11232 [==============================] - 296s 26ms/sample - loss: 0.1054 - acc: 0.8457 - precision_2: 0.9210 - recall_2: 0.8116 - val_loss: 0.0829 - val_acc: 0.8711 - val_precision_2: 0.9578 - val_recall_2: 0.8256\n",
      "Epoch 3/4\n",
      "11232/11232 [==============================] - 278s 25ms/sample - loss: 0.0763 - acc: 0.8837 - precision_2: 0.9561 - recall_2: 0.8339 - val_loss: 0.0691 - val_acc: 0.9007 - val_precision_2: 0.9554 - val_recall_2: 0.8578\n",
      "Epoch 4/4\n",
      "11232/11232 [==============================] - 291s 26ms/sample - loss: 0.0632 - acc: 0.9087 - precision_2: 0.9591 - recall_2: 0.8630 - val_loss: 0.0589 - val_acc: 0.9186 - val_precision_2: 0.9593 - val_recall_2: 0.8779\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=4,  validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2809/2809 [==============================] - 30s 11ms/sample - loss: 0.0589 - acc: 0.9186 - precision_2: 0.9593 - recall_2: 0.8779\n",
      "LSTM Metrics(Test loss Test Accuracy, Precision, & Recall): \n",
      "[0.05887940408374839, 0.9186246, 0.95929503, 0.8778512]\n"
     ]
    }
   ],
   "source": [
    "lstm_metrics = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"LSTM Metrics(Test loss Test Accuracy, Precision, & Recall): \")\n",
    "print(lstm_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 2, 8, 1],\n",
       "       [0, 0, 0, ..., 3, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "y_pred = model.predict(np.array(X_test))\n",
    "y_pred = np.argmax(y_pred,axis=-1)\n",
    "true = np.argmax(np.array(y_test),-1)\n",
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "pred = []\n",
    "actual = []\n",
    "\n",
    "for prediction in range(y_pred.shape[0]):                       \n",
    "    for i in range(max_len):                            \n",
    "        if true[prediction][i]==0:  #skip PAD value so not in DF\n",
    "            pass\n",
    "        else:                                                 \n",
    "            if true[prediction][i]==y_pred[prediction][i]:      \n",
    "                count = count+1                                \n",
    "                total=total+1                                      \n",
    "            pred.append(y_pred[prediction][i])                   \n",
    "            actual.append(true[prediction][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "lstmDF = pd.DataFrame(precision_recall_fscore_support(y_true=actual, y_pred=pred, average=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmDF = lstmDF.drop(columns = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>o</th>\n",
       "      <th>b-loc</th>\n",
       "      <th>b-per</th>\n",
       "      <th>b-org</th>\n",
       "      <th>i-per</th>\n",
       "      <th>i-org</th>\n",
       "      <th>b-misc</th>\n",
       "      <th>i-loc</th>\n",
       "      <th>i-misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.946112</td>\n",
       "      <td>0.772535</td>\n",
       "      <td>0.686459</td>\n",
       "      <td>0.795756</td>\n",
       "      <td>0.731757</td>\n",
       "      <td>0.600962</td>\n",
       "      <td>0.752049</td>\n",
       "      <td>0.584270</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.988812</td>\n",
       "      <td>0.770907</td>\n",
       "      <td>0.755981</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.840614</td>\n",
       "      <td>0.171939</td>\n",
       "      <td>0.543704</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.139738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FScore</th>\n",
       "      <td>0.966991</td>\n",
       "      <td>0.771720</td>\n",
       "      <td>0.719545</td>\n",
       "      <td>0.377596</td>\n",
       "      <td>0.782418</td>\n",
       "      <td>0.267380</td>\n",
       "      <td>0.631126</td>\n",
       "      <td>0.474886</td>\n",
       "      <td>0.229391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support</th>\n",
       "      <td>34233.000000</td>\n",
       "      <td>1423.000000</td>\n",
       "      <td>1254.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>727.000000</td>\n",
       "      <td>675.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>229.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      o        b-loc        b-per        b-org       i-per  \\\n",
       "Precision      0.946112     0.772535     0.686459     0.795756    0.731757   \n",
       "Recall         0.988812     0.770907     0.755981     0.247525    0.840614   \n",
       "FScore         0.966991     0.771720     0.719545     0.377596    0.782418   \n",
       "Support    34233.000000  1423.000000  1254.000000  1212.000000  847.000000   \n",
       "\n",
       "                i-org      b-misc       i-loc      i-misc  \n",
       "Precision    0.600962    0.752049    0.584270    0.640000  \n",
       "Recall       0.171939    0.543704    0.400000    0.139738  \n",
       "FScore       0.267380    0.631126    0.474886    0.229391  \n",
       "Support    727.000000  675.000000  260.000000  229.000000  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstmDF.index = [\"Precision\", \"Recall\", \"FScore\" ,\"Support\"]\n",
    "lstmDF.columns = [index2ner[col] for col in list(set(actual))]\n",
    "lstmDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0],\n",
       "       [    2, 33850,    14,   133,    35,   133,    17,    38,     5,\n",
       "            6],\n",
       "       [    0,   227,  1097,    42,    20,     4,     4,    27,     2,\n",
       "            0],\n",
       "       [    0,   264,     7,   948,     9,    25,     1,     0,     0,\n",
       "            0],\n",
       "       [    0,   509,   134,   224,   300,     5,     8,    31,     1,\n",
       "            0],\n",
       "       [    0,   116,     2,    16,     0,   712,     0,     1,     0,\n",
       "            0],\n",
       "       [    0,   418,    44,     7,     3,    73,   125,    14,    41,\n",
       "            2],\n",
       "       [    1,   175,    80,     5,    10,     3,    13,   367,    11,\n",
       "           10],\n",
       "       [    2,    85,    30,     6,     0,    14,    15,     4,   104,\n",
       "            0],\n",
       "       [    2,   134,    12,     0,     0,     4,    25,     6,    14,\n",
       "           32]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Compute confusion matrix\n",
    "lstmMatrix = confusion_matrix(actual, pred)\n",
    "\n",
    "lstmMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 70, 128)           512000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 70, 1000)          629000    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 70, 10)            10010     \n",
      "=================================================================\n",
      "Total params: 1,151,010\n",
      "Trainable params: 1,151,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len, mask_zero=True))\n",
    "model.add(Bidirectional(SimpleRNN(units=500, return_sequences=True, recurrent_dropout=0.2, dropout=0.2)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy', tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11232 samples, validate on 2809 samples\n",
      "Epoch 1/4\n",
      "11232/11232 [==============================] - 114s 10ms/sample - loss: 0.1579 - acc: 0.8283 - precision_3: 0.8746 - recall_3: 0.7635 - val_loss: 0.0910 - val_acc: 0.8779 - val_precision_3: 0.9240 - val_recall_3: 0.8456\n",
      "Epoch 2/4\n",
      "11232/11232 [==============================] - 116s 10ms/sample - loss: 0.0734 - acc: 0.8959 - precision_3: 0.9452 - recall_3: 0.8573 - val_loss: 0.0562 - val_acc: 0.9246 - val_precision_3: 0.9600 - val_recall_3: 0.8877\n",
      "Epoch 3/4\n",
      "11232/11232 [==============================] - 115s 10ms/sample - loss: 0.0486 - acc: 0.9335 - precision_3: 0.9594 - recall_3: 0.9074 - val_loss: 0.0419 - val_acc: 0.9448 - val_precision_3: 0.9617 - val_recall_3: 0.9273\n",
      "Epoch 4/4\n",
      "11232/11232 [==============================] - 175s 16ms/sample - loss: 0.0372 - acc: 0.9498 - precision_3: 0.9645 - recall_3: 0.9349 - val_loss: 0.0361 - val_acc: 0.9524 - val_precision_3: 0.9623 - val_recall_3: 0.9432\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=4,  validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2809/2809 [==============================] - 24s 9ms/sample - loss: 0.0361 - acc: 0.9524 - precision_3: 0.9623 - recall_3: 0.9432\n",
      "Bidirectional Metrics(Test loss Test Accuracy, Precision, & Recall): \n",
      "[0.03614134113703834, 0.952374, 0.96229714, 0.94322073]\n"
     ]
    }
   ],
   "source": [
    "Bi_metrics = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Bidirectional Metrics(Test loss Test Accuracy, Precision, & Recall): \")\n",
    "print(Bi_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "y_pred = model.predict(np.array(X_test))\n",
    "y_pred = np.argmax(y_pred,axis=-1)\n",
    "true = np.argmax(np.array(y_test),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "pred = []\n",
    "actual = []\n",
    "\n",
    "for prediction in range(y_pred.shape[0]):                       \n",
    "    for i in range(max_len):                            \n",
    "        if true[prediction][i]==0:  #skip PAD value so not in DF\n",
    "            pass\n",
    "        else:                                                 \n",
    "            if true[prediction][i]==y_pred[prediction][i]:      \n",
    "                count = count+1                                \n",
    "                total=total+1                                      \n",
    "            pred.append(y_pred[prediction][i])                   \n",
    "            actual.append(true[prediction][i])                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "birdirectionalDF = pd.DataFrame(precision_recall_fscore_support(y_true=actual, y_pred=pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>o</th>\n",
       "      <th>b-loc</th>\n",
       "      <th>b-per</th>\n",
       "      <th>b-org</th>\n",
       "      <th>i-per</th>\n",
       "      <th>i-org</th>\n",
       "      <th>b-misc</th>\n",
       "      <th>i-loc</th>\n",
       "      <th>i-misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.966453</td>\n",
       "      <td>0.913686</td>\n",
       "      <td>0.834504</td>\n",
       "      <td>0.848309</td>\n",
       "      <td>0.879093</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.881533</td>\n",
       "      <td>0.909677</td>\n",
       "      <td>0.887097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.991353</td>\n",
       "      <td>0.825720</td>\n",
       "      <td>0.852472</td>\n",
       "      <td>0.724422</td>\n",
       "      <td>0.824085</td>\n",
       "      <td>0.550206</td>\n",
       "      <td>0.749630</td>\n",
       "      <td>0.542308</td>\n",
       "      <td>0.480349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FScore</th>\n",
       "      <td>0.978745</td>\n",
       "      <td>0.867479</td>\n",
       "      <td>0.843393</td>\n",
       "      <td>0.781486</td>\n",
       "      <td>0.850701</td>\n",
       "      <td>0.654129</td>\n",
       "      <td>0.810248</td>\n",
       "      <td>0.679518</td>\n",
       "      <td>0.623229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support</th>\n",
       "      <td>34233.000000</td>\n",
       "      <td>1423.000000</td>\n",
       "      <td>1254.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>727.000000</td>\n",
       "      <td>675.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>229.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      o        b-loc        b-per        b-org       i-per  \\\n",
       "Precision      0.966453     0.913686     0.834504     0.848309    0.879093   \n",
       "Recall         0.991353     0.825720     0.852472     0.724422    0.824085   \n",
       "FScore         0.978745     0.867479     0.843393     0.781486    0.850701   \n",
       "Support    34233.000000  1423.000000  1254.000000  1212.000000  847.000000   \n",
       "\n",
       "                i-org      b-misc       i-loc      i-misc  \n",
       "Precision    0.806452    0.881533    0.909677    0.887097  \n",
       "Recall       0.550206    0.749630    0.542308    0.480349  \n",
       "FScore       0.654129    0.810248    0.679518    0.623229  \n",
       "Support    727.000000  675.000000  260.000000  229.000000  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birdirectionalDF.index = [\"Precision\", \"Recall\", \"FScore\" ,\"Support\"]\n",
    "birdirectionalDF.columns = [index2ner[col] for col in list(set(actual))]\n",
    "birdirectionalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33937,    18,    98,    55,    50,    49,    13,     3,    10],\n",
       "       [  163,  1175,    20,    44,     3,     5,    10,     3,     0],\n",
       "       [  148,     7,  1069,    21,     9,     0,     0,     0,     0],\n",
       "       [  208,    40,    43,   878,     5,    10,    28,     0,     0],\n",
       "       [  121,     0,    22,     0,   698,     3,     1,     2,     0],\n",
       "       [  248,    18,    12,    25,    16,   400,     3,     5,     0],\n",
       "       [  136,    10,     9,     9,     1,     1,   506,     1,     2],\n",
       "       [   70,    12,     4,     3,     7,    20,     1,   141,     2],\n",
       "       [   84,     6,     4,     0,     5,     8,    12,     0,   110]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Compute confusion matrix\n",
    "confMatrix = confusion_matrix(actual, pred)\n",
    "\n",
    "confMatrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Bidirectional RNN had the best overall test accuracy at 96% compared to simpleRNN(93.5%) & lstm(91.8%).  o class had the highest numbers(precision, recall & f1 score) for all 3 tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
