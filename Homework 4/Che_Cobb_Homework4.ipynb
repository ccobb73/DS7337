{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk; \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import treebank\n",
    "from nltk.tag import UnigramTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\tRun one of the part-of-speech (POS) taggers available in Python. \n",
    "###### a.\tFind the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    "###### b.\tFind the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence:\n",
      "['All', 'we', 'have', 'to', 'decide', 'is', 'what', 'to', 'do', 'with', 'the', 'time', 'that', 'is', 'given', 'us', '.']\n",
      "\n",
      "POS tags:\n",
      "[('All', 'DT'), ('we', 'PRP'), ('have', 'VBP'), ('to', 'TO'), ('decide', 'VB'), ('is', 'VBZ'), ('what', 'WP'), ('to', 'TO'), ('do', 'VB'), ('with', 'IN'), ('the', 'DT'), ('time', 'NN'), ('that', 'WDT'), ('is', 'VBZ'), ('given', 'VBN'), ('us', 'PRP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "text = word_tokenize(\"All we have to decide is what to do with the time that is given us.\")\n",
    "print(\"Original sentence:\")\n",
    "print(text)\n",
    "print()\n",
    "text_POS = nltk.pos_tag(text)\n",
    "print(\"POS tags:\")\n",
    "print(text_POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence:\n",
      "['She', 'is', 'a', 'history', 'teacher', '.']\n",
      "\n",
      "POS tags:\n",
      "[('She', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('history', 'NN'), ('teacher', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Short-sentence tagging\n",
    "text = word_tokenize(\"She is a history teacher.\")\n",
    "print(\"Original sentence:\")\n",
    "print(text)\n",
    "print()\n",
    "text_POS = nltk.pos_tag(text)\n",
    "print(\"POS tags:\")\n",
    "print(text_POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The POS tagger was unable to reconize the word \"history\" as a adjective since it was acting as an adjective for teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\tRun a different POS tagger in Python. Process the same two sentences from question 1.\n",
    "##### a.\tDoes it produce the same or different output?\n",
    "##### b.\tExplain any differences as best you can.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training set\n",
    "train_data = (treebank.tagged_sents()[:3500])\n",
    "test_data = (treebank.tagged_sents()[3500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence Tagging:\n",
      "[('All', 'DT'), ('we', 'PRP'), ('have', 'VBP'), ('to', 'TO'), ('decide', 'VB'), ('is', 'VBZ'), ('what', 'WP'), ('to', 'TO'), ('do', 'VB'), ('with', 'IN'), ('the', 'DT'), ('time', 'NN'), ('that', 'WDT'), ('is', 'VBZ'), ('given', 'VBN'), ('us', 'PRP'), ('.', '.')]\n",
      "\n",
      "Performance of Unigram tagger:\n",
      "[('All', 'DT'), ('we', 'PRP'), ('have', 'VBP'), ('to', 'TO'), ('decide', 'VB'), ('is', 'VBZ'), ('what', 'WP'), ('to', 'TO'), ('do', 'VBP'), ('with', 'IN'), ('the', 'DT'), ('time', 'NN'), ('that', 'IN'), ('is', 'VBZ'), ('given', 'VBN'), ('us', 'PRP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Long sentence\n",
    "text = word_tokenize(\"All we have to decide is what to do with the time that is given us.\")\n",
    "print(\"Original sentence Tagging:\")\n",
    "print(nltk.pos_tag(text))\n",
    "print()\n",
    "\n",
    "# Unigram Tag\n",
    "ut = UnigramTagger(train_data)\n",
    "print(\"Performance of Unigram tagger:\")\n",
    "print(ut.tag(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence Tagging:\n",
      "[('She', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('history', 'NN'), ('teacher', 'NN'), ('.', '.')]\n",
      "\n",
      "Performance of Unigram tagger:\n",
      "[('She', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('history', 'NN'), ('teacher', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Short sentence\n",
    "text = word_tokenize(\"She is a history teacher.\")\n",
    "print(\"Original sentence Tagging:\")\n",
    "print(nltk.pos_tag(text))\n",
    "print()\n",
    "\n",
    "# Unigram Tag\n",
    "ut = UnigramTagger(train_data)\n",
    "print(\"Performance of Unigram tagger:\")\n",
    "print(ut.tag(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Short sentence still shows a noun for history regardless of what tagger I use, so maybe it is a noun?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\tIn a news article from this week’s news, find a random sentence of at least 10 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.\tLooking at the Penn tag set, manually POS tag the sentence yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Biden--NNP, is--VBZ, not--RB the--DT, only--JJ, candidate--NN, banking--NN, on--IN, a--DT, strong--JJ, finish--NN, in--IN, South--NNP, Carolina--NNP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\tNow run the same sentences through both taggers that you implemented for questions 1 and 2. Did either of the taggers produce the same results as you had created manually?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence:\n",
      "['Biden', 'is', 'not', 'the', 'only', 'candidate', 'banking', 'on', 'a', 'strong', 'finish', 'in', 'South', 'Carolina', '.']\n",
      "\n",
      "POS tags:\n",
      "[('Biden', 'NNP'), ('is', 'VBZ'), ('not', 'RB'), ('the', 'DT'), ('only', 'JJ'), ('candidate', 'NN'), ('banking', 'NN'), ('on', 'IN'), ('a', 'DT'), ('strong', 'JJ'), ('finish', 'NN'), ('in', 'IN'), ('South', 'NNP'), ('Carolina', 'NNP'), ('.', '.')]\n",
      "\n",
      "Performance of Unigram tagger:\n",
      "[('Biden', None), ('is', 'VBZ'), ('not', 'RB'), ('the', 'DT'), ('only', 'RB'), ('candidate', 'NN'), ('banking', 'NN'), ('on', 'IN'), ('a', 'DT'), ('strong', 'JJ'), ('finish', None), ('in', 'IN'), ('South', 'NNP'), ('Carolina', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "text = word_tokenize(\"Biden is not the only candidate banking on a strong finish in South Carolina.\")\n",
    "print(\"Original sentence:\")\n",
    "print(text)\n",
    "print()\n",
    "text_POS = nltk.pos_tag(text)\n",
    "print(\"POS tags:\")\n",
    "print(text_POS)\n",
    "print()\n",
    "ut = UnigramTagger(train_data)\n",
    "print(\"Performance of Unigram tagger:\")\n",
    "print(ut.tag(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.\tExplain any differences between the two taggers and your manual tagging as much as you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The unigram couldn't see Biden is a noun, everything else was basically the same except for ONLY with the POS tagging it 'JJ' and the unigram tagging 'RB'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\tPrepare the train.txt Dataset for insertion into a RNN.\n",
    "##### a.\tThe data is not in proper format.  Each line lists a word and 4 tags.  Your task is to form the words into sequences and form target sequences as well.\n",
    "         i.\tYour target is the last (fourth) tag.\n",
    "##### b.\tSentences are listed vertically.  A blank line indicates a new sentence.  \n",
    "         i.\tForm the sentences into sequences\n",
    "         ii.\tForm the fourth tag into a sequence of targets.\n",
    "##### c.\tEncode the data to integers.  You will need two dictionaries:\n",
    "         i.\tWord to integer\n",
    "         ii.\tTarget Category to integer\n",
    "##### d.\tYou should turn in the functions and code you use to perform this task—I will use them on a hidden dataset to test your success at encoding.  Padding is required—this data should be ready to put into a neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "f = open('train.txt','r')\n",
    "tagged_sentence = []\n",
    "sentence = []\n",
    "\n",
    "for line in f:\n",
    "    if len(line)==0 or line.startswith('-DOCSTART') or line[0]=='\\n':\n",
    "        if len(sentence) >0:\n",
    "            tagged_sentence.append(sentence)\n",
    "            sentence = []\n",
    "        continue\n",
    "    splits = line.split(' ')\n",
    "    splits[-1] = re.sub(r'\\n','',splits[-1])\n",
    "    word = splits[0].lower()\n",
    "    sentence.append([word,splits[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['eu', 'B-ORG'],\n",
       " ['rejects', 'O'],\n",
       " ['german', 'B-MISC'],\n",
       " ['call', 'O'],\n",
       " ['to', 'O'],\n",
       " ['boycott', 'O'],\n",
       " ['british', 'B-MISC'],\n",
       " ['lamb', 'O'],\n",
       " ['.', 'O']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = []\n",
    "tag_list = []\n",
    "\n",
    "for tagged_sentence in tagged_sentence:\n",
    "    sentence, tag_info = zip(*tagged_sentence)\n",
    "    sentence_list.append(list(sentence))\n",
    "    tag_list.append(list(tag_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX length : 113\n",
      "AVG length : 14.501887\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('MAX length : %d' % max(len(l) for l in sentence_list))\n",
    "print('AVG length : %f' % (sum(map(len, sentence_list))/len(sentence_list)))\n",
    "plt.hist([len(s) for s in sentence_list], bins=50)\n",
    "plt.xlabel('Length of samples')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "max_words = 4000\n",
    "\n",
    "vocab = Tokenizer(num_words=max_words, oov_token='OOV')\n",
    "vocab.fit_on_texts(sentence_list)\n",
    "\n",
    "tag = Tokenizer()\n",
    "tag.fit_on_texts(tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 10\n"
     ]
    }
   ],
   "source": [
    "vocab_size = max_words\n",
    "tag_size = len(tag.word_index) + 1\n",
    "print(vocab_size, tag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vocab.texts_to_sequences(sentence_list)\n",
    "y_train = tag.texts_to_sequences(tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[989, 1, 205, 629, 7, 3939, 216, 1, 3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 1, 7, 1, 1, 1, 7, 1, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = vocab.index_word\n",
    "index2ner = tag.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'o',\n",
       " 2: 'b-loc',\n",
       " 3: 'b-per',\n",
       " 4: 'b-org',\n",
       " 5: 'i-per',\n",
       " 6: 'i-org',\n",
       " 7: 'b-misc',\n",
       " 8: 'i-loc',\n",
       " 9: 'i-misc'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_decoded = []\n",
    "for index in X_train[0] : \n",
    "    ex_decoded.append(index2word[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eu', 'OOV', 'german', 'call', 'to', 'boycott', 'british', 'OOV', '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 70\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
    "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=tag_size)\n",
    "y_test = to_categorical(y_test, num_classes=tag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len, mask_zero=True))\n",
    "model.add(LSTM(units=500, return_sequences=True, recurrent_dropout=0.2, dropout=0.2))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 70, 128)           512000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 70, 500)           1258000   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 70, 10)            5010      \n",
      "=================================================================\n",
      "Total params: 1,775,010\n",
      "Trainable params: 1,775,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11232 samples, validate on 2809 samples\n",
      "Epoch 1/4\n",
      " 6656/11232 [================>.............] - ETA: 1:58 - loss: 0.2197 - acc: 0.8174"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=4,  validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2809/2809 [==============================] - 28s 10ms/sample - loss: 0.0577 - acc: 0.9217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9217083"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_index(i):\n",
    "    y_pred = model.predict(np.array([X_test[i]]))\n",
    "    y_pred = np.argmax(y_pred,axis=-1)\n",
    "    true = np.argmax(y_test[i],-1)\n",
    "    \n",
    "    print(\"{:15}|{:5}|{}\".format('word','actual','predicted'))\n",
    "    print(35*\"-\")\n",
    "    \n",
    "    for w,t,pred in zip(X_test[i], true, y_pred[0]):\n",
    "        if w!= 0:\n",
    "            print(\"{:17}:{:7}{}\".format(index2word[w], index2ner[t].upper(),index2ner[pred].upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word           |actual|predicted\n",
      "-----------------------------------\n",
      "ties             :O      O\n",
      "between          :O      O\n",
      "the              :O      O\n",
      "two              :O      O\n",
      "neighbours       :O      O\n",
      ",                :O      O\n",
      "OOV              :O      O\n",
      "also             :O      O\n",
      "over             :O      O\n",
      "a                :O      O\n",
      "military         :O      O\n",
      "accord           :O      O\n",
      "between          :O      O\n",
      "turkey           :B-LOC  B-LOC\n",
      "and              :O      O\n",
      "israel           :B-LOC  B-LOC\n",
      "which            :O      O\n",
      "drew             :O      O\n",
      "strong           :O      O\n",
      "iranian          :B-MISC B-MISC\n",
      "OOV              :O      O\n",
      ",                :O      O\n",
      "have             :O      O\n",
      "improved         :O      O\n",
      "since            :O      O\n",
      "islamist         :B-MISC B-MISC\n",
      "OOV              :B-PER  O\n",
      "erbakan          :I-PER  B-PER\n",
      "took             :O      O\n",
      "over             :O      O\n",
      "as               :O      O\n",
      "turkish          :B-MISC B-MISC\n",
      "prime            :O      O\n",
      "minister         :O      O\n",
      "in               :O      O\n",
      "june             :O      O\n",
      ".                :O      O\n"
     ]
    }
   ],
   "source": [
    "### input a result from the index to see what the actual and predicted values were.\n",
    "result_index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
